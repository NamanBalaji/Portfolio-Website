<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=icon href=https://namanbalaji.github.io/Portfolio-Website/images/0.jpg type=image/gif><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet><link rel=stylesheet href=https://namanbalaji.github.io/Portfolio-Website/css/font.css media=all><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-DWJJVE27WD","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script><meta property="og:title" content="Map Reduce"><meta property="og:description" content="MapReduce: Simplified Data Processing on Large Clusters MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key.
Programs written in this functional style are automatically parallelised and executed on a large cluster of commodity machines."><meta property="og:type" content="article"><meta property="og:url" content="https://namanbalaji.github.io/Portfolio-Website/blogs/map-reduce/"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2022-06-18T16:48:06+05:30"><meta property="article:modified_time" content="2022-06-18T16:48:06+05:30"><meta property="og:site_name" content="Naman Balaji"><meta name=twitter:card content="summary"><meta name=twitter:title content="Map Reduce"><meta name=twitter:description content="MapReduce: Simplified Data Processing on Large Clusters MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key.
Programs written in this functional style are automatically parallelised and executed on a large cluster of commodity machines."><link rel=stylesheet href=https://namanbalaji.github.io/Portfolio-Website/bootstrap-5/css/bootstrap.min.css media=all><link rel=stylesheet href=https://namanbalaji.github.io/Portfolio-Website/css/header.css media=all><link rel=stylesheet href=https://namanbalaji.github.io/Portfolio-Website/css/footer.css media=all><link rel=stylesheet href=https://namanbalaji.github.io/Portfolio-Website/css/theme.css media=all><style>:root{--text-color:#343a40;--text-secondary-color:#6c757d;--background-color:#eaedf0;--secondary-background-color:#64ffda1a;--primary-color:#007bff;--secondary-color:#f8f9fa;--text-color-dark:#e4e6eb;--text-secondary-color-dark:#b0b3b8;--background-color-dark:#18191a;--secondary-background-color-dark:#212529;--primary-color-dark:#ffffff;--secondary-color-dark:#212529}body{font-size:1rem;font-weight:400;line-height:1.5;text-align:left}</style><meta name=description content><link rel=stylesheet href=https://namanbalaji.github.io/Portfolio-Website/css/single.css><script defer src=https://namanbalaji.github.io/Portfolio-Website/fontawesome-5/all-5.15.4.js></script><title>Map Reduce | Naman Balaji</title></head><body class=light onload=loading()><script src=https://namanbalaji.github.io/Portfolio-Website/bootstrap-5/js/bootstrap.bundle.js></script>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header><nav class="pt-3 navbar navbar-expand-lg"><div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5"><a class="navbar-brand primary-font text-wrap" href=https://namanbalaji.github.io/Portfolio-Website/><img src=https://namanbalaji.github.io/Portfolio-Website/images/0.jpg width=30 height=30 class="d-inline-block align-top">
Naman Balaji</a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarContent aria-controls=navbarContent aria-expanded=false aria-label="Toggle navigation"><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="24" data-view-component="true"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button><div class="collapse navbar-collapse text-wrap primary-font" id=navbarContent><ul class="navbar-nav ms-auto text-center"><li class="nav-item navbar-text"><a class=nav-link href=https://namanbalaji.github.io/Portfolio-Website/#about aria-label=about>About</a></li><li class="nav-item navbar-text"><a class=nav-link href=https://namanbalaji.github.io/Portfolio-Website/#experience aria-label=experience>Experience</a></li><li class="nav-item navbar-text"><a class=nav-link href=https://namanbalaji.github.io/Portfolio-Website/#education aria-label=education>Education</a></li><li class="nav-item navbar-text"><a class=nav-link href=https://namanbalaji.github.io/Portfolio-Website/#projects aria-label=projects>Projects</a></li><li class="nav-item navbar-text"><a class=nav-link href=https://namanbalaji.github.io/Portfolio-Website/#contact aria-label=contact>Contact</a></li><li class="nav-item navbar-text"><a class=nav-link href=https://namanbalaji.github.io/Portfolio-Website/blogs title="Blog posts">Blog</a></li></ul><div class=text-center><button id=theme-toggle><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div></div></nav></header><div id=content><section id=single><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-9"><div class=pr-lg-4><div class="title mb-5"><h1 class="text-center mb-4">Map Reduce</h1><div class=text-center><small>|</small>
Jun 18, 2022</div></div><article class="page-content p-2"><h1 id=mapreduce-simplified-data-processing-on-large-clustershttpsstaticgoogleusercontentcommediaresearchgooglecomenarchivemapreduce-osdi04pdf><a href=https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf>MapReduce: Simplified Data Processing on Large Clusters</a></h1><p>MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a <em>map</em> function that processes a key/value pair to generate a set of intermediate key/value pairs, and a <em>reduce</em> function that merges all intermediate values associated with the same intermediate key.</p><p>Programs written in this functional style are automatically parallelised and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program&rsquo;s execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilise the resources of a large distributed system.</p><h2 id=what-is-map-reduce>What is Map-Reduce?</h2><p>MapReduce is an interface that enables automatic parallelization and distribution of <strong>large-scale computation</strong>, while <strong>abstracting</strong> over **“the messy details of parallelization, fault-tolerance, data distribution and load balancing” **.</p><p>As the name suggests, MapReduce is inspired by map and reduce functions present in many functional languages, which allows them to parallelize large computation easily and use re-execution as a key mechanism to deal with failures.
The abstraction is inspired by the <em>map</em> and <em>reduce</em> primitives present in Lisp and many other functional languages. Map and reduce operations allows easy parallelisation at the same time that re-execution serves as the primary mechanism for fault-tolerance.</p><h2 id=what-were-the-problems-mapreduce-was-trying-to-solve>What were the problems MapReduce was trying to solve?</h2><p>Before MapReduce, Google has implemented hundreds of computations that process a large amount of raw data to compute various derived data.</p><p>They found that most of these computations were conceptually straightforward. However, the difficulty comes in the form of large input data whose computation has to be distributed across up to thousands of machines to complete in a reasonable time. Some of these issues that arise with distributed computation are:</p><ol><li>How to parallelize the computation</li><li>How to distribute the large input/output data</li><li>How to handle failures</li></ol><p>The main goal of MapReduce is hence to provide an easy-to-us interface even for programmers without experience in distributed and parallel systems by abstracting all the details of parallelization, fault-tolerance, data distribution, and load balancing away.</p><p>A benefit that comes with the main goal is that it becomes easier to improve the performance of a computation process by simply adding new machines to the cluster because MapReduce automatically handles all the abstractions for programmers.</p><h2 id=architecture>Architecture</h2><p>We can express a computation using MapReduce in the form of 2 user-defined functions: Map and Reduce.</p><p><code>map :=(k1,v1):= (k1, v1):=(k1,v1) —> list(k2,v2)list(k2, v2)list(k2,v2)</code>
 </p><p><code>reduce :=(k2,list(v2)):= (k2, list(v2)):=(k2,list(v2)) —> list(v3)list(v3)list(v3)</code></p><p><strong>Map:</strong> Takes a data input (key, value) pair and produces a set of intermediate (key, value) pairs. The MapReduce library groups together all intermediate values associated with the same intermediate key I and passes them to the Reduce function.</p><p><strong>Reduce:</strong> Accepts an intermediate key and a set of values for that key. It merges these values to form a possibly smaller set of values. Note that the intermediate values are supplied to the reduce function via an iterator. This allows us to handle lists of values that are too large to fit in memory.</p><p>Note that in practical use cases, the output from the Reduce operations is often fed as input into another MapReduce job, or possibly another distributed application.</p><h3 id=overall-execution-of-mapreduce>Overall Execution of MapReduce</h3><p><img src=https://namanbalaji.github.io/Portfolio-Website/images/blog/mapreduce.png alt></p><p>Figure 1: High level overview of an execution of a MapReduce job. Adapted from [1].</p><p>Note that the input data is partitioned into a set of MMM splits. These splits can then be processed in parallel by different machines. The Reduce invocations are also partitioned by the intermediate key space into RRR splits using a user-defined partitioning function. Both MMM and RRR are specified by the user.</p><p>Figure 1 shows the overall flow of a MapReduce job. The following sequence of actions will occur when a user calls a MapReduce function (the numbered labels in Figure 1 correspond to the numbers in the list below):</p><ol><li>Input files are split into MMM pieces typically 16-64MB (Google uses GPS to partition input data automatically) by the user program. It then starts up many copies of the program on a cluster of machines.</li><li>One of the copies of the program is special – the master. The rest are workers that are assigned work by the master. There are M map tasks and R reduce tasks to assign. The master picks idle workers and assigns each one a map task or a reduce task.<ul><li>Note that in 2004, network bandwidth is a huge bottleneck and the authors wanted to minimise passing data through the network. As described in the Section of Locality Optimisation, the Master tends to schedule map jobs to machines containing the input data (thus, the map jobs are usually run locally).</li></ul></li><li>A worker who is assigned a map task reads the contents of the corresponding input split. It parses key/value pairs out of the input data and passes each pair to the user-defined Map function. The intermediate key/value pairs produced by the Map function are buffered in the memory of the map worker.</li><li>Periodically, the buffered pairs are written to local disk, partitioned into R regions by the partitioning function. The locations of these buffered pairs on the local disk are passed back to the master, who is responsible for forwarding these locations to the reduce workers.<ul><li>Note that reduce jobs only begin after all map jobs are completed (refer to the FAQ Section).</li></ul></li><li>When a reduce worker is notified by the master about these locations, it uses remote procedure calls to read the buffered data from the local disks of the map workers. When a reduce worker has read all intermediate data, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The sorting is needed because typically many different keys map to the same reduce task. If the amount of intermediate data is too large to fit in memory, an external sort is used.</li><li>The reduce worker iterates over the sorted intermediate data and for each unique intermediate key encountered, it passes the key and the corresponding set of intermediate values to the user’s Reduce function. The output of the Reduce function is appended to a final output file for this reduce partition.<ul><li>After all map jobs are completed, reduce worker will pull the intermediate data (from a partition) from the local disk of all map workers.</li><li>Reduce workers will sort the intermediate keys.</li><li>Pass the intermediate keys in order to Reduce function.</li><li>Output of Reduce function is appended to a final output file.</li></ul></li><li>When all map tasks and reduce tasks have been completed, the master wakes up the user program. At this point, the MapReduce call in the user program returns back to the user code.</li></ol><h3 id=master-data-structures>Master data structures</h3><p>For each map task and reduce task, master stores the state (<em>idle</em>, <em>in-progress</em>, or <em>completed</em>) and the identity of the worker machine.</p><p>For each completed map task, the master stores the locations and sizes of the <em>R</em> intermediate file regions produced by the map task. Updates to this location and size information are received as map tasks are compelted. The information is pushed incrementally to workers that have <em>in-progress</em> reduce tasks.</p><h2 id=fault-tolerance>Fault tolerance</h2><h3 id=worker-failure>Worker failure</h3><p>The master pings every worker periodically. If no response is received from a worker in a certain amount of time, the master marks the worker as failed. Any map tasks completed by the worker are reset back to their initial <em>idle</em> state, and therefore become eligible for scheduling on other workers. Similarly, any map task or reduce task in progress on a failed worker is also reset to <em>idle</em> and becomes eligible for rescheduling.</p><p>Completed map tasks are re-executed on failure because their output is stored on the local disks of the failed machine and is therefore inaccessible. Completed reduce tass do not need to be re-executed since their output is stored in a global file system.</p><p>When a map task is executed first by worker <em>A</em>, and later executed by worker <em>B</em> (because <em>A</em> failed), all workers executing reduce tasks are notified of the re-execution. Any reduce task that has not already read the data from worker <em>A</em> will read the data from worker <em>B</em>.</p><p>The MapReduce master simply re-executes the work done by unreachable worker machines and continues to make forward progress.</p><h3 id=master-failure>Master failure</h3><p>It&rsquo;s easy to make the master write periodic checkpoints of the master data structures. If the master task dies, a new copy can be started from the last checkpointed state. Current implementation aborts the MapReduce computation if the master fails.</p><h2 id=refinement>Refinement</h2><h3 id=partitioning-function>Partitioning function</h3><p>Users of MapReduce specify the number of reduce task/output files that they desire (<em>R</em>). A default partitioning function is provided that uses hashing (peg: <code>hash(key) mod R</code>), which tends to result in fairly well-balanced partitions. In some cases, it is useful to partition data by some other function of the key, for example sometimes the output keys are URLs, and is convenient to have a single host end up in the same output file. A partitioning function can be provided to MapReduce, for example <code>hash(Hostname(urlkey)) mod R</code>.</p><h3 id=ordering-guarantees>Ordering guarantees</h3><p>Within a given partition, the intermediate key/value pairs are guaranteed to be processed in increasing key order, which makes it easy to generate a sorted output file per partition.</p><h3 id=combiner-function>Combiner function</h3><p>MapReduce allows the user to specify a <em>Combiner</em> function that does partial merging of the data before it is sent over the network.</p><p>The <em>Combiner</em> function is executed on each machine that performs a map task. The difference between a reduce function and a combiner function is how the MapReduce library handles the output of the function. The output of a reduce function is written to the final output file. The output of a combiner function is written to an intermediate field that will be sent to a reduce task.</p><h2 id=usage-exmples>Usage exmples</h2><ul><li>Distributed Grep: The map function emits a line if it matches a supplied pattern. The reduce function is an identity function that just copies the supplied intermediate data to the output.</li><li>Count of URL access frequency: The map function processes logs of a web page requests and outputs <code>&lt;URL, 1></code>. The reduce function adds together all values for the same URL and emits a <code>&lt;URL, total count></code> pair.</li><li>Distributed sort: The map functions extracts the key from each record, and emits a <code>&lt;key, record></code> pair. The reduce function emits all pairs unchanged.</li></ul><h2 id=when-is-mapreduce-not-suitable>When is MapReduce not suitable?</h2><ol><li>When you need real-time processing, MapReduce may not be the fastest option.</li><li>It’s not always very easy to implement each and everything into a sequence of Map and Reduce function.</li><li>When your intermediate processes need to talk to each other(MapReduce jobs are run in isolation).</li><li>When you need to handle streaming data.</li><li>When you can get the desired result in a local machine. “It’s obviously less painful to configure and manage a standalone system as compared to a distributed system.”</li></ol><h2 id=what-are-the-key-lessons-from-mapreduce>What are the key lessons from MapReduce?</h2><ol><li>Restricting the programming model makes it easier to parallelize and distribute computations and to even make such computation fault tolerance.<ul><li>E.g. For MapReduce, we restrict the model to accept key/value pairs, and the output also is key/value pair.</li></ul></li><li>Redundant executions can be used to reduce the impact of slow machines (stragglers) and to handle machine failures and data loss.<ul><li>In the event of worker failures, MapReduce master simply re-executes the work done by the unreachable worker and continues to make forward progress.</li><li>Refer to Backup Tasks in Section 3.6 [1] on how MapReduce tackles the issue of “straggler”: a machine that takes an unusually long time to complete one of the last few map or reduce tasks, thus prolong the total time needed. (tldr: the master schedules backup executions on the remaining in-progress tasks when the MapReduce operation is close to completion)</li></ul></li></ol><h2 id=faq>FAQ</h2><h5 id=1-does-the-shuffle-process-in-reduce-workers-pulling-of-intermediate-data-from-all-map-workers-happen-concurrently-with-reduce-operations>1. Does the shuffle process in Reduce workers (pulling of intermediate data from all map workers) happen concurrently with reduce operations?</h5><p> 
No, it doesn’t. The reduce worker will alternate between shuffling data from map workers, and passing the intermediate data to sort and Reduce function.</p><h5 id=2-do-the-reduce-operations-occur-concurrently-with-map-operations-no-you-can-think-of-the-map-and-reduce-operations-like-occurring-in-batches-the-reduce-workers-have-to-wait-for-all-map-jobs-to-be-completed-to-begin-working-on-shuffling-sorting-and-passing-data-into-reduce-functions>2. Do the reduce operations occur concurrently with map operations? No. You can think of the map and reduce operations like occurring in batches. The reduce workers have to wait for all map jobs to be completed to begin working on shuffling, sorting and passing data into Reduce functions.</h5><p> 
This is because MapReduce guarantees ordering, i.e. within a given partition, the intermediate key/value pairs are processed in increasing key order (refer to Section 4.2 of [1]).
In other words, in order for reduce operations to begin, the entire partition must be collected first, then sorted, before the calls to Reduce functions can be made.
The only way to be sure we have the entire partition is to wait for all map operations to be completed so that all input slices have been processed.</p></article></div></div><div class="col-sm-12 col-md-12 col-lg-3"><div class=sticky-sidebar><aside class=toc><h5>Table Of Contents</h5><div class=toc-content><nav id=TableOfContents><ul><li><a href=#what-is-map-reduce>What is Map-Reduce?</a></li><li><a href=#what-were-the-problems-mapreduce-was-trying-to-solve>What were the problems MapReduce was trying to solve?</a></li><li><a href=#architecture>Architecture</a><ul><li><a href=#overall-execution-of-mapreduce>Overall Execution of MapReduce</a></li><li><a href=#master-data-structures>Master data structures</a></li></ul></li><li><a href=#fault-tolerance>Fault tolerance</a><ul><li><a href=#worker-failure>Worker failure</a></li><li><a href=#master-failure>Master failure</a></li></ul></li><li><a href=#refinement>Refinement</a><ul><li><a href=#partitioning-function>Partitioning function</a></li><li><a href=#ordering-guarantees>Ordering guarantees</a></li><li><a href=#combiner-function>Combiner function</a></li></ul></li><li><a href=#usage-exmples>Usage exmples</a></li><li><a href=#when-is-mapreduce-not-suitable>When is MapReduce not suitable?</a></li><li><a href=#what-are-the-key-lessons-from-mapreduce>What are the key lessons from MapReduce?</a></li><li><a href=#faq>FAQ</a><ul><li></li></ul></li></ul></nav></div></aside><aside class=tags><h5>Tags</h5><ul class="tags-ul list-unstyled list-inline"><li class=list-inline-item><a href=https://namanbalaji.github.io/Portfolio-Website/tags/map-reduce target=_blank>Map-Reduce</a></li><li class=list-inline-item><a href=https://namanbalaji.github.io/Portfolio-Website/tags/6.824 target=_blank>6.824</a></li><li class=list-inline-item><a href=https://namanbalaji.github.io/Portfolio-Website/tags/distributed-systems target=_blank>Distributed Systems</a></li></ul></aside><aside class=social><h5>Social</h5><div class=social-content><ul class=list-inline><li class="list-inline-item text-center"><a target=_blank href="https://twitter.com/share?text=Map%20Reduce&url=https%3a%2f%2fnamanbalaji.github.io%2fPortfolio-Website%2fblogs%2fmap-reduce%2f"><i class="fab fa-twitter"></i></a></li><li class="list-inline-item text-center"><a target=_blank href="https://api.whatsapp.com/send?text=Map%20Reduce: https%3a%2f%2fnamanbalaji.github.io%2fPortfolio-Website%2fblogs%2fmap-reduce%2f"><i class="fab fa-whatsapp"></i></a></li><li class="list-inline-item text-center"><a target=_blank href="mailto:?subject=Map%20Reduce&body=Check out this site https%3a%2f%2fnamanbalaji.github.io%2fPortfolio-Website%2fblogs%2fmap-reduce%2f"><i class="fa fa-envelope"></i></a></li></ul></div></aside></div></div></div><div class=row><div class="col-sm-12 col-md-12 col-lg-9 p-4"><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//namanbalaji.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div></div><button class="p-2 px-3" onclick=topFunction() id=topScroll>
<i class="fas fa-angle-up"></i></button></section><script>var topScroll=document.getElementById("topScroll");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?topScroll.style.display="block":topScroll.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script></div><footer><div class="container py-3" id=recent-posts><div class="h3 text-center text-secondary py-3">Recent posts</div><div class="row justify-content-center"><div class="col-lg-4 col-md-6 pt-2"><div class="card h-100"><div class="card-body bg-transparent p-3 shadow-sm"><a href=https://namanbalaji.github.io/Portfolio-Website/blogs/raft/ class="primary-font card-title"><h5 class="card-title bg-transparent" title="Understanding Raft Consensus">Understanding Raft …</h5></a><div class="card-text secondary-font"><p>In Search of an Understandable Consensus Algorithm Raft is a consensus algorithm, meaning that it is designed to facilitate a set of computers agreeing on a state of the world (more on exactly how the state of the world is represented later), even when communications between the computers in the set …</p></div></div><div class="mt-auto card-footer"><span class=float-start>June 23, 2022</span>
<a href=https://namanbalaji.github.io/Portfolio-Website/blogs/raft/ class="float-end btn btn-outline-info btn-sm">Read</a></div></div></div><div class="col-lg-4 col-md-6 pt-2"><div class="card h-100"><div class="card-body bg-transparent p-3 shadow-sm"><a href=https://namanbalaji.github.io/Portfolio-Website/blogs/gfs/ class="primary-font card-title"><h5 class="card-title bg-transparent" title="GFS Paper Summary">GFS Paper Summary</h5></a><div class="card-text secondary-font"><p>The Google File System (2003) - Paper Summary Why are we reading the GFS paper? Incorporates many of the recurring themes in Distributed Systems: parallel performance, fault tolerance, replication, consistency. Successful real-world design. BigTable, MapReduce built on top of GFS. Well-written …</p></div></div><div class="mt-auto card-footer"><span class=float-start>June 19, 2022</span>
<a href=https://namanbalaji.github.io/Portfolio-Website/blogs/gfs/ class="float-end btn btn-outline-info btn-sm">Read</a></div></div></div><div class="col-lg-4 col-md-6 pt-2"><div class="card h-100"><div class="card-body bg-transparent p-3 shadow-sm"><a href=https://namanbalaji.github.io/Portfolio-Website/blogs/map-reduce/ class="primary-font card-title"><h5 class="card-title bg-transparent" title="Map Reduce">Map Reduce</h5></a><div class="card-text secondary-font"><p>MapReduce: Simplified Data Processing on Large Clusters MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce …</p></div></div><div class="mt-auto card-footer"><span class=float-start>June 18, 2022</span>
<a href=https://namanbalaji.github.io/Portfolio-Website/blogs/map-reduce/ class="float-end btn btn-outline-info btn-sm">Read</a></div></div></div></div></div><div class="text-center pt-2"><span class=px-1><a href=https://github.com/NamanBalaji aria-label=github><svg xmlns="http://www.w3.org/2000/svg" width="2.7em" height="2.7em" viewBox="0 0 1792 1792"><path d="M522 1352q-8 9-20-3-13-11-4-19 8-9 20 3 12 11 4 19zm-42-61q9 12 0 19-8 6-17-7t0-18q9-7 17 6zm-61-60q-5 7-13 2-10-5-7-12 3-5 13-2 10 5 7 12zm31 34q-6 7-16-3-9-11-2-16 6-6 16 3 9 11 2 16zm129 112q-4 12-19 6-17-4-13-15t19-7q16 5 13 16zm63 5q0 11-16 11-17 2-17-11 0-11 16-11 17-2 17 11zm58-10q2 10-14 14t-18-8 14-15q16-2 18 9zm964-956v960q0 119-84.5 203.5T1376 1664h-224q-16 0-24.5-1t-19.5-5-16-14.5-5-27.5v-239q0-97-52-142 57-6 102.5-18t94-39 81-66.5 53-105T1386 856q0-121-79-206 37-91-8-204-28-9-81 11t-92 44l-38 24q-93-26-192-26t-192 26q-16-11-42.5-27T578 459.5 492 446q-44 113-7 204-79 85-79 206 0 85 20.5 150t52.5 105 80.5 67 94 39 102.5 18q-40 36-49 103-21 10-45 15t-57 5-65.5-21.5T484 1274q-19-32-48.5-52t-49.5-24l-20-3q-21 0-29 4.5t-5 11.5 9 14 13 12l7 5q22 10 43.5 38t31.5 51l10 23q13 38 44 61.5t67 30 69.5 7 55.5-3.5l23-4q0 38 .5 103t.5 68q0 22-11 33.5t-22 13-33 1.5H416q-119 0-203.5-84.5T128 1376V416q0-119 84.5-203.5T416 128h960q119 0 203.5 84.5T1664 416z"/></svg></a></span><span class=px-1><a href=https://www.linkedin.com/in/naman-balaji-a35602178/ aria-label=linkedin><svg xmlns="http://www.w3.org/2000/svg" width="2.4em" height="2.4em" fill="#fff" aria-label="LinkedIn" viewBox="0 0 512 512"><rect width="512" height="512" fill="#0077b5" rx="15%"/><circle cx="142" cy="138" r="37"/><path stroke="#fff" stroke-width="66" d="M244 194v198M142 194v198"/><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg></a></span><a href=https://www.instagram.com/naman.merengues/ aria-label=instagram><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="48" height="48"><radialGradient id="yOrnnhliCrdS2gy~4tD8ma" cx="19.38" cy="42.035" r="44.899" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#fd5"/><stop offset=".328" stop-color="#ff543f"/><stop offset=".348" stop-color="#fc5245"/><stop offset=".504" stop-color="#e64771"/><stop offset=".643" stop-color="#d53e91"/><stop offset=".761" stop-color="#cc39a4"/><stop offset=".841" stop-color="#c837ab"/></radialGradient><path fill="url(#yOrnnhliCrdS2gy~4tD8ma)" d="M34.017 41.99l-20 .019c-4.4.004-8.003-3.592-8.008-7.992l-.019-20c-.004-4.4 3.592-8.003 7.992-8.008l20-.019c4.4-.004 8.003 3.592 8.008 7.992l.019 20C42.014 38.383 38.417 41.986 34.017 41.99z"/><radialGradient id="yOrnnhliCrdS2gy~4tD8mb" cx="11.786" cy="5.54" r="29.813" gradientTransform="matrix(1 0 0 .6663 0 1.849)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#4168c9"/><stop offset=".999" stop-color="#4168c9" stop-opacity="0"/></radialGradient><path fill="url(#yOrnnhliCrdS2gy~4tD8mb)" d="M34.017 41.99l-20 .019c-4.4.004-8.003-3.592-8.008-7.992l-.019-20c-.004-4.4 3.592-8.003 7.992-8.008l20-.019c4.4-.004 8.003 3.592 8.008 7.992l.019 20C42.014 38.383 38.417 41.986 34.017 41.99z"/><path fill="#fff" d="M24 31c-3.859.0-7-3.14-7-7s3.141-7 7-7 7 3.14 7 7-3.141 7-7 7zm0-12c-2.757.0-5 2.243-5 5s2.243 5 5 5 5-2.243 5-5-2.243-5-5-5z"/><circle cx="31.5" cy="16.5" r="1.5" fill="#fff"/><path fill="#fff" d="M30 37H18c-3.859.0-7-3.14-7-7V18c0-3.86 3.141-7 7-7h12c3.859.0 7 3.14 7 7v12c0 3.86-3.141 7-7 7zM18 13c-2.757.0-5 2.243-5 5v12c0 2.757 2.243 5 5 5h12c2.757.0 5-2.243 5-5V18c0-2.757-2.243-5-5-5H18z"/></svg></a></div><div class="container py-4"><div class="row justify-content-center"><div class="col-md-4 text-center"><div class=pb-2><a href=https://namanbalaji.github.io/Portfolio-Website/ title="Naman Balaji"><img alt="Footer logo" src=https://namanbalaji.github.io/Portfolio-Website/images/0.jpg height=40px width=40px></a></div>&copy; 2022 All Rights Reserved<div class=text-secondary>Made with
<span class=text-danger>&#10084;</span>
and
<a href=https://github.com/gurusabarish/hugo-profile target=_blank title="Designed and developed by gurusabarish">Hugo Profile</a></div></div></div></div></footer><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))});var tooltipTriggerList=[].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]')),tooltipList=tooltipTriggerList.map(function(e){return new bootstrap.Tooltip(e)})</script><script>let loadingIcons;function loading(){myVar=setTimeout(showPage,100)}function showPage(){try{document.getElementById("loading-icons").style.display="block"}catch{}}</script></body></html>